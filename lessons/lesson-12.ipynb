{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High level\n",
    "What is web scraping?\n",
    "> Web scraping (web harvesting or web data extraction) is a computer software technique of extracting information from websites.\n",
    "\n",
    "What questions can you answer with web scraping?\n",
    "- What TV shows are airing tonight?\n",
    "- What is the name and price of the first 5 results for X on ebay?\n",
    "- How many words is the wiki page for X?\n",
    "- Has X been updated recently with this text?\n",
    "- is X band playing at Doug Fir any time soon?\n",
    "- is that [refurbished Baratza](http://www.baratza.com/product/encore-refurb/) in stock yet?\n",
    "- Are tickets available for sale yet?\n",
    "\n",
    "\n",
    "Ethics of web scraping\n",
    "- https://news.ycombinator.com/item?id=12345693\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n",
    "name | Purpose\n",
    "-----|--------\n",
    "[Selector Gadget](http://selectorgadget.com/) | find css selectors visually\n",
    "[CSS selector cheat-sheet](http://www.cheetyr.com/css-selectors) | CSS selector reference\n",
    "[BeautifulSoup4](http://beautiful-soup-4.readthedocs.io/en/latest/) | Parse HTML webpages with selectors\n",
    "[requests](http://docs.python-requests.org/en/master/) | Connect to and download webpages (HTML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML\n",
    "**HyperText Markup Language** \n",
    "\n",
    "It's the code that forms websites.  We won't be learning HTML today, but we'll learn enough to understand how we can navigate it.\n",
    " \n",
    "#### HTML is made up of elements as its base components\n",
    "\n",
    "Elements have structure:\n",
    "\n",
    "![element structure](https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/HTML_element_structure.svg/330px-HTML_element_structure.svg.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When nested inside eachother, they give the document form\n",
    "\n",
    "![html structure](http://www.htmlgoodies.com/img/2007/06/page_container.gif)\n",
    "\n",
    "\n",
    "This can also be viewed as a tree-like structure.  Here's the above when we only care about *children* and *ancestors*\n",
    "![html tree-like structure](http://www.htmlgoodies.com/img/2007/06/flowChart2.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step will be to actually get the website's html.  To do that, we'll be using the 3rd-party *requests*\\* module.\n",
    "This simulates:\n",
    "1. opening your browser\n",
    "2. typing in the url you want to visit\n",
    "3. selecting 'View Source'\n",
    "4. copying the text\n",
    "5. pasting it into a variable.\n",
    "\n",
    "\\* we could do this using just the std-lib, but requests is popular enough you'll encounter it often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/hassanshamim/python_foundations/master/README.md'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response # If you're not familiar with HTTP codes, this output might be totally useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(response) # let's see what this *response object* can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response.ok # Did the website/server respond properly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following result is Markup, not HTML.  Why?\n",
    "The page we requested was just plain text - not HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response.text # the contents.  In this example it's markup, not HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's try a real web page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response2 = requests.get('http://www.hackoregon.org/upcoming-courses')\n",
    "response2.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response2.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAY! It's working.  But what if the thing we're getting isn't text?  What if it's an image?\n",
    "\n",
    "Well, that's out of scope for today, but the general process is:\n",
    "- get response from image url - `requests.get('http://www.website.com/file/image.jpeg')`\n",
    "- get the binary data out, **not** the text - `response.content`\n",
    "- save it to a file or render it as in image in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Data we want\n",
    "If we want all the dates on a webpage, we can't just search for 'dates'\n",
    "We either:\n",
    "- have to know **where the dates occur** consistently in the webpage (structurally)\n",
    "- have to know **how the dates are marked** (are they all in an element with a certain keyword? like 'arrival-date')\n",
    "- or we have to **know how dates are formatted**, and look for everything that follows that format (i.e. some slashes then numbers then slashes then more numbers - this is what regular expressiosn do)\n",
    "\n",
    "We'll be using a combination of the first two, with some help from Selector Gadget\n",
    "\n",
    "\n",
    "\n",
    "### Beautiful Soup cheatsheet\n",
    "\n",
    "**NOTE**: the traversal methods (select, find, .h3) can be used on tags as well as the whole soup\n",
    "\n",
    "command | what it does\n",
    "--------|------------\n",
    "bs4.BeautifulSoup(data, 'html.parser') | creates our soup object that we use to scan the document\n",
    "soup.find_all | return a *list* of tag objects that match our query\n",
    "soup.find | returns the *first* tag object that matches our query\n",
    "soup.select | uses **css selectors** to query our data.  returns the first\n",
    "soup.select_all | same as above, but returns a list\n",
    "soup.h3 | returns the first h3 tag matched.  same as `soup.find('h3')`  Works for any tag name\n",
    "tag.text | returns text inside\n",
    "tag.get_text() | fetches inner text ignoring any tags\n",
    "tag.stripped_strings | returns a *generator* of component strings with whitespace removed.  Pass to `list()` to get a list object from the generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hack University Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = '.span-6 h2 , .span-8 h2 , .span-7 h2 , .span-7 strong'\n",
    "\n",
    "soup = bs4.BeautifulSoup(response2.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = soup.select(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tag in result:\n",
    "    print(type(tag), tag.name, tag.string, sep=',  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(t.stripped_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[r.text for r in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = bs4.BeautifulSoup('<div class=\"sqs-block-content\" id=\"yui_3_17_2_1_1480579287682_383\"><h2 id=\"yui_3_17_2_1_1480579287682_382\">Applied Data Visualization</h2><h3>LEVEL: Advanced</h3><h3>START DATE: JAN 23RD, MON + WED, 6-9PM</h3><h3>DURATION: 8 WEEKS</h3><h3>COST $850</h3><h3>REACT OFFICE HOURS: +$250, TUES + THURS, 6-9PM</h3><h3>Instructor: David Daniel</h3></div>', 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.find_all('h3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.find_all(['h2', 'h3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = soup.select('.span-6 h2 , .span-8 h2 , .span-7 h2 , .span-7 strong')\n",
    "[tag.text for tag in result if tag.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_url = 'https://www.yelp.com/search?find_desc=pizza&find_loc=Portland'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_page = requests.get(yelp_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_soup = bs4.BeautifulSoup(yelp_page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_soup.body.find_all('li', {'class': 'regular-search-result'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_soup.body.find_all('li', class_='regular-search-result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = yelp_soup.body.select('li.regular-search-result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.find('a', class_='biz-name').span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.select_one('a.biz-name span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.select_one('div.i-stars').get('title').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(r.address.stripped_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pagination\n",
    "\n",
    "After we hit 'next' in the yelp search page, we get the second page of results.  the url looks like this:\n",
    "\n",
    "`https://www.yelp.com/search?find_desc=pizza&find_loc=Portland&start=10`\n",
    "\n",
    "Same as our original URL, but notice the **&start=10**  This is called a **query parameter**.  It's a key/value pair (in this case *start* and *10* respectively) that yelp uses to find and create the page we're looking for.\n",
    "\n",
    "We can manually or programmatically adjust this to get the page we want.  Alternatively, we could find the 'next' button every time and follow that link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hundreth_page = requests.get('https://www.yelp.com/search?find_desc=pizza&find_loc=Portland&start=1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same as the above\n",
    "params = {'find_desc': 'pizza', 'find_loc': 'Portland OR', 'start': 100}\n",
    "hundreth_page = requests.get('https://www.yelp.com/search', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hundreth_page.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requests.utils.urlparse('https://www.yelp.com/search?find_desc=pizza&start=100&find_loc=Portland+OR').query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hundreth_page.ok\n",
    "soup = bs4.BeautifulSoup(hundreth_page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.select('li.regular-search-result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.select('#super-container > div > div > div > div > h3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wiki_page_url = 'https://en.wikipedia.org/wiki/ISO_4217'\n",
    "wiki_html = requests.get(wiki_page_url).text\n",
    "wsoup = bs4.BeautifulSoup(wiki_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wsoup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wsoup.select_one('#Active_codes').parent.next_sibling.next_sibling.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "currency_table = wsoup.select_one('h2 + p + table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row = currency_table.select('tr')[1]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wsoup.select('h2 + p + table tr')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requests.utils.quote('Portland, OR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice:\n",
    "- write a script to play the wikipedia game.\n",
    "- write a script to download all the comics from xkcd.\n",
    "- Write a function that pulls the current weather\n",
    "- Just think of a website you use often and play around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional References:\n",
    "- https://automatetheboringstuff.com/chapter11/\n",
    "- [HTTP Status Codes](http://www.restapitutorial.com/httpstatuscodes.html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python-foundations]",
   "language": "python",
   "name": "conda-env-python-foundations-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
